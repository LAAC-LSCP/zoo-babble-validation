---
title: "Supplementary materials to: Describing vocalizations in young children: A big data approach through citizen science annotations"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
---


```{r setup, include=FALSE}
library(groundhog)
groundhog.day="2021-02-23"
groundhog.library('tidyverse', groundhog.day)
groundhog.library('dplyr', groundhog.day)
groundhog.library('ggplot2', groundhog.day)
groundhog.library('rmarkdown', groundhog.day)
groundhog.library('caret', groundhog.day)
groundhog.library('scales', groundhog.day)
groundhog.library('kableExtra', groundhog.day)
groundhog.library('rel', groundhog.day)
groundhog.library('ggpubr', groundhog.day)
groundhog.library('lme4', groundhog.day)
groundhog.library('e1071', groundhog.day)
groundhog.library('rjson', groundhog.day)

# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

#document session info
capture.output(sessionInfo(),file="supmat-lastknit_session_info.txt")


knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8) 

dodiv=function(x) x/sum(x, na.rm=T)
```


## History:

- 2020-11-03 first version
- 2021-03-08 increased reproducibility


## Correspondence between lab & zooniverse annotation at the level of segments


Here we look at to what extent zooniverse and lab annotations match at the level of individual segments. Each data point is one segment (using LENA segmentation). Unlike in the main paper, here we will show results before applying the ordered rules that give prevalence to canonical, non-canonical, laughing, crying (in that order). 

```{r gen-seg-allinfo}
## PHASE 3 -- Generate views on the data: majority judgment on the segment

#dictionary that relates chunk to segment created by Chiara
dict <- fromJSON(file="dict_4.json") 
dict.simple=unlist(dict)
length(dict.simple) 
dict=data.frame(cbind(dict.simple,gsub(".$","",as.character(names(dict.simple)))))
colnames(dict)<-c("chunk","segmentId_DB")
length(levels(factor(dict$chunk)))
#33728 chunks
length(levels(factor(dict$segmentId_DB)))
#12170 segments
#NOTE!!! THERE ARE TWO CHUNKS MISSING FROM THIS DICTIONARY!!!

#laboratory annotations
read.csv("lab_annotations.csv")->lab_jud
dim(lab_jud)
#11982 segments

sum(lab_jud$segmentId_DB %in% levels(factor(dict$segmentId_DB))) #11980 in common
sum(!(lab_jud$segmentId_DB %in% levels(factor(dict$segmentId_DB)))) #2 fund in lab but not dict
sum(!(levels(factor(dict$segmentId_DB)) %in% lab_jud$segmentId_DB )) #190 found in dict but not in lab

#assuming that we should follow lab data, I'll kick out any segment not in there

#chunk info
read.csv("chunks_maj_judgments.csv",colClasses="factor")->maj_jud
maj_jud$AudioData=gsub(".mp3","",maj_jud$filename)


# next I need to match up the segments with the chunks
sum(dict.simple %in% maj_jud$AudioData) # 33727 found
sum(!(dict.simple %in% maj_jud$AudioData)) # 1 not found

rownames(dict)<-dict$chunk
maj_jud$segmentId_DB <- dict[maj_jud$AudioData,"segmentId_DB"]
length(levels(factor(maj_jud$segmentId_DB))) #12170 segments

#in postprocess, the following code is executed, but not here, because we want to keep info about chunk-majority-judgment within each segment
  # #generate majority at the segment level using our rule:
  # # canonical > non-canonical > crying > laughing > junk
  # table(maj_jud$segmentId_DB,maj_jud$Answer)->mytab
  # mytype<-ifelse(mytab[,"Canonical"]>0,"Canonical",
  #                ifelse(mytab[,"Non-Canonical"]>0,"Non-Canonical",
  #                       ifelse(mytab[,"Crying"]>0,"Crying",
  #                              ifelse(mytab[,"Laughing"]>0,"Laughing",
  #                                     ifelse(mytab[,"Junk"]>0,"Junk",""
  #                                     )))))

table(maj_jud$segmentId_DB,maj_jud$Answer)->mytab #we still create the table with the number of judgments

# #but the mytype vector will include n's of each type
# mytype <- rep("",n=length(levels(factor(maj_jud$segmentId_DB))))
# mytype<-ifelse(mytab[,"Canonical"]>0,paste(mytype,"Ca",mytab[,"Canonical"],sep=""),mytype)
# mytype<-ifelse(mytab[,"Non-Canonical"]>0,paste(mytype,"N",mytab[,"Non-Canonical"],sep=""),mytype)
# mytype<-ifelse(mytab[,"Crying"]>0,paste(mytype,"Cr",mytab[,"Crying"],sep=""),mytype)
# mytype<-ifelse(mytab[,"Laughing"]>0,paste(mytype,"L",mytab[,"Laughing"],sep=""),mytype)
# mytype<-ifelse(mytab[,"Junk"]>0,paste(mytype,"J",mytab[,"Junk"],sep=""),mytype)
# 
# levels(factor(mytype))
# #there are over 350 combinations!! So we won't do that

mytype <- rep("",n=length(levels(factor(maj_jud$segmentId_DB))))
mytype<-ifelse(mytab[,"Canonical"]>0,paste(mytype,"Ca",sep=""),mytype)
mytype<-ifelse(mytab[,"Non-Canonical"]>0,paste(mytype,"N",sep=""),mytype)
mytype<-ifelse(mytab[,"Crying"]>0,paste(mytype,"Cr",sep=""),mytype)
mytype<-ifelse(mytab[,"Laughing"]>0,paste(mytype,"L",sep=""),mytype)
mytype<-ifelse(mytab[,"Junk"]>0,paste(mytype,"J",sep=""),mytype)
levels(factor(mytype))
# about 30 unique combinations, let's go for it

zoo_jud=cbind(row.names(mytab),mytype)
colnames(zoo_jud)<-c("segmentId_DB","Answer")

merge(zoo_jud,lab_jud,by="segmentId_DB")->all_jud
dim(all_jud)
#11980 segments
levels(factor(all_jud$ChildID)) 
length(levels(factor(all_jud$ChildID)))#all 20 kids here

# create columns with names that match the following chunks
all_jud$Zoon_classif = all_jud$Answer
all_jud$lab = all_jud$Major_Choice

# for the lab case, simplify
all_jud$lab[all_jud$lab=="Canonical syllables"]<-"Ca"
all_jud$lab[all_jud$lab=="Words"]<-"Ca"
all_jud$lab[all_jud$lab=="Crying"]<-"Cr"
all_jud$lab[all_jud$lab=="Laughing"]<-"L"
all_jud$lab[all_jud$lab=="Don't mark"]<-"J"
all_jud$lab[all_jud$lab=="None"]<-""
all_jud$lab[all_jud$lab=="Non-canonical syllables"]<-"N"

table(all_jud$lab)
table(all_jud$Zoon_classif)

#remove classes with fewer than 10 instances
table(all_jud$Zoon_classif)[table(all_jud$Zoon_classif)<10]
all_jud=all_jud[!(all_jud$Zoon_classif %in% names(table(all_jud$Zoon_classif)[table(all_jud$Zoon_classif)<10])),]

#remove classes with no majority judgment
all_jud=all_jud[all_jud$Zoon_classif !="",]
all_jud=all_jud[all_jud$lab !="",]
dim(all_jud)


all_jud$Zoon_classif=factor(all_jud$Zoon_classif)
all_jud$lab=factor(all_jud$lab, levels=levels(all_jud$Zoon_classif))
```



```{r cm}

mycf=confusionMatrix(all_jud$lab, all_jud$Zoon_classif, dnn = c("Lab","Zooniverse"))
conf_tab=mycf$table
# this package uses sensitivity & specificity
#Sensitivity=recall
#Specificity=precision
mycf
```

### Precision

Precision means: If a segment was called X by zooniverse coders, what proportion of the time was it called X by lab coders?


```{r prec}
colsums=colSums(conf_tab)
my_conf_tab=conf_tab
for(i in 1:dim(my_conf_tab)[2]) my_conf_tab[,i]=my_conf_tab[,i]/colsums[i]
colSums(my_conf_tab)
prop_cat=data.frame(my_conf_tab*100) #generates precision because columns
prop_cat$id=paste(prop_cat$Lab,prop_cat$Zooniverse)
colnames(prop_cat)[3]<-"pr"
data.frame(conf_tab)->stall
stall$id=paste(stall$Lab,stall$Zooniverse)
stall=merge(stall,prop_cat[c("id","pr")])
ggplot(data = stall, mapping = aes(y = Lab, x=Zooniverse)) +
 geom_tile(aes(fill= rescale(pr)), colour = "white") +
  geom_text(aes(label = paste(round(pr),"%")), vjust = -1,size=2) +
#  geom_text(aes(label = Freq), vjust = 1,size=1) +
  scale_fill_gradient(low = "white", high = "red", name = "Percentage") +
     theme(legend.position = "none") +
  xlab("Zooniverse") + ylab("Lab") +
  ggtitle("Precision")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

### Recall

Recall means: If a segment was called X by lab coders, what proportion of the time was it called X by zooniverse coders?

```{r rec}
rowsums=rowSums(conf_tab)
my_conf_tab=conf_tab
for(i in 1:dim(my_conf_tab)[1]) my_conf_tab[,i]=my_conf_tab[,i]/rowsums[i]
rowSums(my_conf_tab)
prop_cat=data.frame(conf_tab/rowSums(conf_tab)*100)  #generates recall because rows
prop_cat$id=paste(prop_cat$Lab,prop_cat$Zooniverse)
colnames(prop_cat)[3]<-"rec"
data.frame(conf_tab)->stall
stall$id=paste(stall$Lab,stall$Zooniverse)
stall=merge(stall,prop_cat[c("id","rec")])
ggplot(data = stall, mapping = aes(y = Lab, x=Zooniverse)) +
 geom_tile(aes(fill= rescale(rec)), colour = "white") +
  geom_text(aes(label = paste(round(rec),"%")), vjust = -1,size=2) +
  geom_text(aes(label = Freq), vjust = 1,size=1) +
  scale_fill_gradient(low = "white", high = "red", name = "Percentage") +
     theme(legend.position = "none") +
  xlab("Zooniverse") + ylab("Lab") +
  ggtitle("Recall")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

## Read in & clean up final data

```{r read-in}

read.csv("key_info.csv")->x
rownames(x)<-x$X


read.csv(".chunks_maj_judgments.csv")->chunks

read.csv("zoo_lab_maj_judgments.csv")->data_all

label_options=c("Canonical" , "Non-Canonical"  ,     "Crying"   ,    "Laughing",        "Junk" )

#use better names
data_all$Zoon_classif=data_all$Answer

# create lab column with easier to read correspondance
data_all$lab<-as.character(data_all$Major_Choice)
data_all$lab[data_all$lab=="Non-canonical syllables"]<-"Non-Canonical"
data_all$lab[data_all$lab=="Canonical syllables"]<-"Canonical"
data_all$lab[data_all$lab %in% c("Don't mark","None")]<-"Junk"
data_all$lab=factor(data_all$lab,levels=label_options)
#apply same factor levels as zooniverse so that we can do symmetrical confusion matrices

#add binomials for Linguistic Proportion
data_all$lab_ling=ifelse(data_all$lab %in% c("Canonical","Non-Canonical"),1,0)
data_all$zoo_ling=ifelse(data_all$Zoon_classif %in% c("Canonical","Non-Canonical"),1,0)
data_all$lab_ling[data_all$lab=="Junk"]<-NA
data_all$zoo_ling[data_all$lab=="Junk"]<-NA

#add binomials for Canonical Proportion
data_all$lab_can=data_all$zoo_can=NA
data_all$lab_can[data_all$lab=="Canonical"]<-1
data_all$lab_can[data_all$lab=="Non-Canonical"]<-0
data_all$zoo_can[data_all$Zoon_classif=="Canonical"]<-1
data_all$zoo_can[data_all$Zoon_classif=="Non-Canonical"]<-0


demo_data=read.csv("demo-data.tsv",sep ="\t")
#add filenames to demo data, to be used later
demo_data_fn <- demo_data %>% 
     left_join(select(data_all, filename, ChildID), by = c("ChildID"))
demo_data_fn<-unique(demo_data_fn)

```

```{r clean up, echo=F}
#dim(data_all) #11980    16
# remove non-majority labels from lab
data_all[data_all$Num_Agreement>0,]->data_all
#dim(data_all) # 11647    16

# remove non-majority labels from zooniverse
data_all[data_all$Zoon_classif %in% label_options,]->data_all
#dim(data_all) # 11268    16


#and reset the factors for cleanliness
data_all$Zoon_classif=factor(data_all$Zoon_classif, levels=label_options)
data_all$lab=factor(data_all$lab, levels=label_options)
sample_data<-cbind(data_all$lab,data_all$Zoon_classif)


table_zoon=round(table(data_all$Zoon)/sum(table(data_all$Zoon))*100,2)
table_lab=round(table(data_all$lab)/sum(table(data_all$lab))*100,2)
```

```{r prepare data by child, echo=F}

#get the ns by child, then calculate the linguistic proportion & canonical proportion, separately for zooniverse & lab
ztab=table(data_all$filename,data_all$Zoon_classif)
z_lp =rowSums(ztab[,c("Canonical","Non-Canonical")])/rowSums(ztab[,-which(colnames(ztab) %in% c("Junk"))])
z_cp =ztab[,c("Canonical")]/rowSums(ztab[,c("Canonical","Non-Canonical")])

ltab=table(data_all$filename,data_all$lab)
l_lp =rowSums(ltab[,c("Canonical","Non-Canonical")])/rowSums(ltab[,-which(colnames(ztab) %in% c("Junk"))])
l_cp =ltab[,c("Canonical")]/rowSums(ltab[,c("Canonical","Non-Canonical")])

#and also get Junk from zooniverse
z_Junk=ztab[,c("Junk")]/rowSums(ztab)

  
#put all the proportions together
if(sum(rownames(ztab)==rownames(ltab))==dim(ztab)[1]) proportions=cbind(rownames(ztab),z_lp,z_cp,l_lp,l_cp,z_Junk) else print("oops this code needs to be more complex because we don't have the same kids for the two proportions")
colnames(proportions)[1]<-"filename"

#ages=aggregate(data_all$Age,by=list(data_all$ChildID),mean) #this is a weird way of adding ages, since all of the ages for a given child should be the same if there is only one recording, and if there are multiple recordings, then we should not get the mean
#improvement: now we merge with a demo data tab, but note this is merged with child id, so the problem of multiple recs per child is still there

# Created demo_data with filenames. Use filenames instead of childIDs to merge proportions and demo data.

merge(proportions,demo_data_fn,by="filename")->proportions
colnames(proportions)[dim(proportions)[2]]<-"Age"

#cbinding results in text, so we numerize the proportions
for(thisvar in c("z_lp","z_cp","l_lp","l_cp","z_Junk")) proportions[,thisvar]=as.numeric(as.character(proportions[,thisvar]))

#add median Junk
proportions$median_Junk<-ifelse(proportions$z_Junk<median(proportions$z_Junk),"lower_Junk","higher_Junk")

#summary(proportions)

merge(data_all,proportions,all=T)->data_all
```

## Separate confusion matrices for Angelman syndrome children

```{r}
# CM with just AS kids
data_AS<-subset(data_all, Diagnosis=="AngelmanSyndrome")
mycf=confusionMatrix(data_AS$lab, data_AS$Zoon_classif, dnn = c("Lab","Zooniverse"))
conf_tab=mycf$table
mycf
```

```{r prec2AS}
colsums=colSums(conf_tab)
my_conf_tab=conf_tab
for(i in 1:5) my_conf_tab[,i]=my_conf_tab[,i]/colsums[i]
colSums(my_conf_tab)
prop_cat=data.frame(my_conf_tab*100) #generates precision because columns
prop_cat$id=paste(prop_cat$Lab,prop_cat$Zooniverse)
colnames(prop_cat)[3]<-"pr"
data.frame(conf_tab)->stall
stall$id=paste(stall$Lab,stall$Zooniverse)
stall=merge(stall,prop_cat[c("id","pr")])
ggplot(data = stall, mapping = aes(y = Lab, x=Zooniverse)) +
 geom_tile(aes(fill= rescale(pr)), colour = "white") +
  geom_text(aes(label = paste(round(pr),"%")), vjust = -1,size=8) +
  geom_text(aes(label = Freq), vjust = 1,size=8) +
  scale_fill_gradient(low = "white", high = "red", name = "Proportion") +
     theme(legend.position = "none") +
  xlab("Zooniverse") + ylab("Lab") +
  ggtitle("Precision")+theme(text = element_text(size=20),
        axis.text.x = element_text(angle=90, hjust=1))

```


```{r recall2_AS}
prop_cat=data.frame(conf_tab/rowSums(conf_tab)*100)  #generates recall because rows
prop_cat$id=paste(prop_cat$Lab,prop_cat$Zooniverse)
colnames(prop_cat)[3]<-"rec"
data.frame(conf_tab)->stall
stall$id=paste(stall$Lab,stall$Zooniverse)
stall=merge(stall,prop_cat[c("id","rec")])
ggplot(data = stall, mapping = aes(y = Lab, x=Zooniverse)) +
 geom_tile(aes(fill= rescale(rec)), colour = "white") +
  geom_text(aes(label = paste(round(rec),"%")), vjust = -1,size=8) +
  geom_text(aes(label = Freq), vjust = 1,size=8) +
  scale_fill_gradient(low = "white", high = "red", name = "Proportion") +
     theme(legend.position = "none") +
  xlab("Zooniverse") + ylab("Lab") +
  ggtitle("Recall")+theme(text = element_text(size=20),
        axis.text.x = element_text(angle=90, hjust=1))

```

## Separate confusion matrices with just the low risk controls

```{r}
# CM with just TD kids
data_TD<-subset(data_all, Diagnosis=="Low-RiskControl")
mycf=confusionMatrix(data_TD$lab, data_TD$Zoon_classif, dnn = c("Lab","Zooniverse"))
conf_tab=mycf$table
mycf
```

```{r prec3AS}
colsums=colSums(conf_tab)
my_conf_tab=conf_tab
for(i in 1:5) my_conf_tab[,i]=my_conf_tab[,i]/colsums[i]
colSums(my_conf_tab)
prop_cat=data.frame(my_conf_tab*100) #generates precision because columns
prop_cat$id=paste(prop_cat$Lab,prop_cat$Zooniverse)
colnames(prop_cat)[3]<-"pr"
data.frame(conf_tab)->stall
stall$id=paste(stall$Lab,stall$Zooniverse)
stall=merge(stall,prop_cat[c("id","pr")])
ggplot(data = stall, mapping = aes(y = Lab, x=Zooniverse)) +
 geom_tile(aes(fill= rescale(pr)), colour = "white") +
  geom_text(aes(label = paste(round(pr),"%")), vjust = -1,size=8) +
  geom_text(aes(label = Freq), vjust = 1,size=8) +
  scale_fill_gradient(low = "white", high = "red", name = "Proportion") +
     theme(legend.position = "none") +
  xlab("Zooniverse") + ylab("Lab") +
  ggtitle("Precision")+theme(text = element_text(size=20),
        axis.text.x = element_text(angle=90, hjust=1))

```


```{r recall3}
prop_cat=data.frame(conf_tab/rowSums(conf_tab)*100)  #generates recall because rows
prop_cat$id=paste(prop_cat$Lab,prop_cat$Zooniverse)
colnames(prop_cat)[3]<-"rec"
data.frame(conf_tab)->stall
stall$id=paste(stall$Lab,stall$Zooniverse)
stall=merge(stall,prop_cat[c("id","rec")])
ggplot(data = stall, mapping = aes(y = Lab, x=Zooniverse)) +
 geom_tile(aes(fill= rescale(rec)), colour = "white") +
  geom_text(aes(label = paste(round(rec),"%")), vjust = -1,size=8) +
  geom_text(aes(label = Freq), vjust = 1,size=8) +
  scale_fill_gradient(low = "white", high = "red", name = "Proportion") +
     theme(legend.position = "none") +
  xlab("Zooniverse") + ylab("Lab") +
  ggtitle("Recall")+theme(text = element_text(size=20),
        axis.text.x = element_text(angle=90, hjust=1))

```
